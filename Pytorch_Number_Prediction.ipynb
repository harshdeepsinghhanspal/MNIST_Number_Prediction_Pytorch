{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3y7QRNxRFG5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVWH6lWpRkFz",
        "outputId": "c9141b80-3c86-4b12-bc28-a2e08108c842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 55.5MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.63MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.1MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.05MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Data preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load MNIST dataset\n",
        "train_dataset = MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UwiGG2-R9Y8"
      },
      "outputs": [],
      "source": [
        "# Define CNN model\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 22 * 22, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "model = CNNModel().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1rOUksUSDTe",
        "outputId": "e33ca6b0-e8f0-4c44-bc35-6aff5120590a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 227.7634, Accuracy: 96.36%\n",
            "Epoch [2/10], Loss: 80.5061, Accuracy: 98.69%\n",
            "Epoch [3/10], Loss: 51.5841, Accuracy: 99.14%\n",
            "Epoch [4/10], Loss: 35.2337, Accuracy: 99.41%\n",
            "Epoch [5/10], Loss: 24.5463, Accuracy: 99.54%\n",
            "Epoch [6/10], Loss: 17.3779, Accuracy: 99.71%\n",
            "Epoch [7/10], Loss: 13.0625, Accuracy: 99.79%\n",
            "Epoch [8/10], Loss: 11.6679, Accuracy: 99.78%\n",
            "Epoch [9/10], Loss: 9.3733, Accuracy: 99.84%\n",
            "Epoch [10/10], Loss: 8.8483, Accuracy: 99.84%\n"
          ]
        }
      ],
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0, 0, 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Metrics\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Epoch [{epoch+1}/10], Loss: {running_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), \"model_state.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chXI9eAsSFGC"
      },
      "outputs": [],
      "source": [
        "# Reload the model\n",
        "model = CNNModel().to(device)\n",
        "model.load_state_dict(torch.load(\"model_state.pth\"))\n",
        "model.eval()\n",
        "\n",
        "# Prediction function\n",
        "def predict_image(image_path):\n",
        "    img = Image.open(image_path).convert('L').resize((28, 28))\n",
        "    img_tensor = transforms.ToTensor()(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(img_tensor)\n",
        "        prediction = output.argmax(dim=1).item()\n",
        "\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict custom images\n",
        "print(predict_image('img_3.jpg'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9lhBSyQ67ex",
        "outputId": "97f7de36-8123-4fdd-e7ae-4e0ab1ebc0b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict custom images\n",
        "print(predict_image('img_17.jpg'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2pUE9byR3xn",
        "outputId": "8618b9f6-51c1-4b6b-87a2-41a171a30c12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict custom images\n",
        "print(predict_image('img_24.jpg'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo37EX-7R82T",
        "outputId": "9a11816f-1562-4668-b582-07f0c458f83e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eYxXKPWUSC1k"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}